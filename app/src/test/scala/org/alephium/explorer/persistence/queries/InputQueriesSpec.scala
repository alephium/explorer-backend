// Copyright (c) Alephium
// SPDX-License-Identifier: LGPL-3.0-only

package org.alephium.explorer.persistence.queries

import org.scalacheck.Gen
import slick.jdbc.PostgresProfile.api._

import org.alephium.explorer.AlephiumFutureSpec
import org.alephium.explorer.GenDBModel._
import org.alephium.explorer.persistence.{DatabaseFixtureForEach, TestDBRunner}
import org.alephium.explorer.persistence.model.InputEntity
import org.alephium.explorer.persistence.queries.InputQueries._
import org.alephium.explorer.persistence.queries.result.{InputFromTxQR, InputQR}
import org.alephium.explorer.persistence.schema.InputSchema

class InputQueriesSpec extends AlephiumFutureSpec with DatabaseFixtureForEach with TestDBRunner {

  "insertInputs" should {
    "insert and ignore inputs" in {

      def runTest(existingAndUpdated: Seq[(InputEntity, InputEntity)]) = {
        // fresh table
        exec(InputSchema.table.delete)

        val existing = existingAndUpdated.map(_._1) // existing inputs
        val ignored  = existingAndUpdated.map(_._2) // updated inputs

        // insert existing
        exec(insertInputs(existing))
        exec(InputSchema.table.result) should contain allElementsOf existing

        // insert should ignore existing inputs
        exec(insertInputs(ignored)) is 0
        exec(InputSchema.table.result) should contain allElementsOf existing
      }

      info("Test with random data size generated by ScalaCheck")
      forAll(Gen.listOf(updatedInputEntityGen()))(runTest)

      /** Following two test insert larger queries to test maximum number of parameters allowed by
        * Postgres per query i.e. [[Short.MaxValue]].
        *
        * See <a href="https://github.com/alephium/explorer-backend/issues/160">#160</a>
        */
      info(s"Large: Test with fixed '${Short.MaxValue}' data size")
      Gen
        .listOfN(Short.MaxValue, updatedInputEntityGen())
        .sample
        .foreach(runTest)

      info(s"Large: Test with fixed '${Short.MaxValue + 1}' data size")
      Gen
        .listOfN(Short.MaxValue + 1, updatedInputEntityGen())
        .sample
        .foreach(runTest)
    }
  }

  "inputsFromTxs" should {
    "read from inputs table" when {
      "empty" in {
        // clear table
        exec(InputSchema.table.delete)
        exec(InputSchema.table.length.result) is 0

        forAll(Gen.listOf(inputEntityGen())) { inputs =>
          // run query
          val hashes = inputs.map(input => (input.txHash, input.blockHash))
          val actual = exec(InputQueries.inputsFromTxs(hashes))

          // query output size is 0
          actual.size is 0
        }
      }

      "non-empty" in {
        forAll(Gen.listOf(inputEntityGen())) { inputs =>
          // persist test-data
          exec(InputSchema.table.delete)
          exec(InputSchema.table ++= inputs)

          // run query
          val hashes = inputs.map(input => (input.txHash, input.blockHash))
          val actual = exec(InputQueries.inputsFromTxs(hashes))

          // expected query result
          val expected =
            inputs.map { entity =>
              InputFromTxQR(
                txHash = entity.txHash,
                inputOrder = entity.inputOrder,
                hint = entity.hint,
                outputRefKey = entity.outputRefKey,
                unlockScript = entity.unlockScript,
                outputRefTxHash = entity.outputRefTxHash,
                outputRefAddress = entity.outputRefAddress,
                outputRefGrouplessAddress = entity.outputRefGrouplessAddress,
                outputRefAmount = entity.outputRefAmount,
                outputRefTokens = entity.outputRefTokens,
                contractInput = entity.contractInput
              )
            }

          actual should contain theSameElementsAs expected
        }
      }
    }
  }

  "getInputsQuery" should {
    "read inputs table" when {
      "empty" in {
        // table is empty
        exec(InputSchema.table.length.result) is 0

        forAll(inputEntityGen()) { input =>
          // run query
          val actual =
            exec(InputQueries.getInputsQuery(input.txHash, input.blockHash))

          // query output size is 0
          actual.size is 0
        }
      }
    }

    "non-empty" in {
      forAll(Gen.listOf(inputEntityGen())) { inputs =>
        // no-need to clear the table for each iteration.
        exec(InputSchema.table ++= inputs)

        // run query for each input
        inputs foreach { input =>
          val actual =
            exec(InputQueries.getInputsQuery(input.txHash, input.blockHash))

          // expected query result
          val expected: InputQR =
            InputQR(
              hint = input.hint,
              outputRefKey = input.outputRefKey,
              unlockScript = input.unlockScript,
              outputRefTxHash = input.outputRefTxHash,
              outputRefAddress = input.outputRefAddress,
              outputRefGrouplessAddress = input.outputRefGrouplessAddress,
              outputRefAmount = input.outputRefAmount,
              outputRefTokens = input.outputRefTokens,
              contractInput = input.contractInput
            )

          actual.toList should contain only expected
        }
      }
    }
  }

  "getMainChainInputs" should {
    "return main_chain InputEntities in order" in {
      forAll(Gen.listOf(inputEntityGen())) { inputs =>
        exec(InputSchema.table.delete)
        exec(InputSchema.table ++= inputs)

        val expected = inputs.filter(_.mainChain).sortBy(_.timestamp)

        // Ascending order
        locally {
          val actual = exec(InputQueries.getMainChainInputs(true))
          actual should contain inOrderElementsOf expected
        }

        // Descending order
        locally {
          val expectedReversed = expected.reverse
          val actual           = exec(InputQueries.getMainChainInputs(false))
          actual should contain inOrderElementsOf expectedReversed
        }
      }
    }
  }
}
